{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driven-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "class smo_algo:\n",
    "    def __init__(self,train_data_features,labels,reg_strength,tolerance):\n",
    "        self.X = train_data_features\n",
    "        self.c_labels = labels\n",
    "        self.C = reg_strength\n",
    "        self.tol = tolerance\n",
    "        self.num_lagrange,self.theta_hat_dim = np.shape(self.X)\n",
    "        self.lagrange_muls = np.zeros(self.num_lagrange)\n",
    "        self.errors = np.zeros(self.num_lagrange)\n",
    "        self.epsilon = 10**(-3)\n",
    "        self.theta0_hat = 0\n",
    "        self.theta_hat = np.zeros(self.theta_hat_dim)\n",
    "        \n",
    "    def discriminant_score(self,i):\n",
    "        return self.theta0_hat + float(np.dot(self.theta_hat.T,self.X[i]))\n",
    "        \n",
    "    def compute_error(self,i2):\n",
    "        return self.discriminant_score(i2) - self.c2\n",
    "    \n",
    "    def get_non_bound_indexes(self):\n",
    "        return np.where(np.logical_and(self.lagrange_muls > 0,self.lagrange_muls<=self.C))[0]\n",
    "    \n",
    "    def get_maximum_change_lagrange(self,non_bound_indices):\n",
    "        i1 = -1\n",
    "        if len(non_bound_indices) > 1:\n",
    "            max = 0\n",
    "            \n",
    "            for j in non_bound_indices:\n",
    "                E1 = self.errors[j] - self.c_labels[j]\n",
    "                step = abs(E1 - self.E2)\n",
    "                if step > max:\n",
    "                    max = step\n",
    "                    i1 = j\n",
    "        return i1\n",
    "    \n",
    "    def take_cordinate_ascent_step(self,i1,i2):\n",
    "        if i1 == i2:\n",
    "            return False\n",
    "        \n",
    "        lambda1 = self.lagrange_muls[i1]\n",
    "        c1 = self.c_labels[i1]\n",
    "        X1 = self.X[i1]\n",
    "        E1 = self.compute_error(i1)\n",
    "        \n",
    "        labels_prod = c1 * self.c2\n",
    "        \n",
    "        if c1 != self.c2:\n",
    "            L = max(0,self.lambda2-lambda1)\n",
    "            H = min(self.C,self.lambda2+lambda1)\n",
    "        else:\n",
    "            L = max(0,self.lambda2+lambda1-self.C)\n",
    "            H = min(self.C,self.lambda2+lambda1)\n",
    "            \n",
    "        if L == H:\n",
    "            return False\n",
    "        \n",
    "        k11 = np.dot(X1.T,X1)\n",
    "        k12 = np.dot(X1,self.X[i2])\n",
    "        k22 = np.dot(self.X[i2],self.X[i2])\n",
    "        \n",
    "        second_derivative = k11 + k22 - k12\n",
    "        \n",
    "        if double_derivative > 0:\n",
    "            lambda2_final = self.lambda2 + self.c2*(E1 - self.E2)/double_derivative\n",
    "            \n",
    "            if lambda2_final < L:\n",
    "                lambda2_final = L\n",
    "            elif lambda2_final > H:\n",
    "                lambda2_final = H\n",
    "                \n",
    "        if abs(lambda2_final - self.lambda2)< self.epsilon:\n",
    "            return False\n",
    "        \n",
    "        lambda1_final = lambda1 + labels_prod * (self.lambda2 - lambda2_final)\n",
    "        theta0_hat_final = self.compute_theta0_hat(E1,lambda1,lambda1_final,lambda2_final,k11,k12,k22,c1)\n",
    "        delta_theta0_hat = theta0_hat_final - self.theta0_hat\n",
    "        self.theta0_hat = theta0_hat_final\n",
    "        \n",
    "        self.theta_hat = self.theta_hat + c1*(lambda1_final - lambda1)*X1 + self.c2*(lambda2_final - self.lambda2)*self.X2\n",
    "        \n",
    "        delta_i1 = c1*(lambda1_final - lambda1)\n",
    "        delta_i2 = c2*(lambda2_final - lambda2)\n",
    "        \n",
    "        for i in range(self.num_lagrange):\n",
    "            if self.lagrange_muls[i] > 0 and self.lagrange_muls[i] <= self.C:\n",
    "                self.errors[i] = self.errors[i] + delta_i1 * np.dot(X1,self.X[i]) + delta_i2 * np.dot(X2,self.X[i]) - delta_theta0_hat\n",
    "            \n",
    "        self.errors[i1] = 0\n",
    "        self.errors[i2] = 0\n",
    "        self.lagrange_muls[i1] = lambda1_final\n",
    "        self.lagrange_muls[i2] = lambda2_final\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def compute_theta0_hat(self,E1,lambda1,lambda1_final,lambda2_final,k11,k12,k22,c1):\n",
    "        \n",
    "        theta0_hat1 = E1 + c1*(lambda1_final - lambda1)*k11 + self.c2*(lambda2_final - self.lambda2)*k12 + self.theta0_hat\n",
    "        theta0_hat2 = self.E2 + c1*(lambda1_final - lambda1)*k12 + self.c2*(lambda2_final - self.lambda2)*k22 + self.theta0_hat\n",
    "        \n",
    "        if lambda1_final > 0 and lambda1_final < self.C:\n",
    "            theta0_hat_final = theta0_hat1\n",
    "        elif lambda2_final > 0 and lambda2_final < self.C:\n",
    "            theta0_hat_final = theta0_hat2\n",
    "        else:\n",
    "            theta0_hat_final = (theta0_hat1 + theta0_hat2)/2.0\n",
    "        return theta0_hat_final\n",
    "        \n",
    "            \n",
    "        \n",
    "    def check_example(self,i2):\n",
    "        self.c2 = self.c_label[i2]\n",
    "        self.lambda2 = self.lagrange_muls[i2]\n",
    "        self.X2 = self.X[i2]\n",
    "        self.E2 = self.compute_error(i2)\n",
    "        \n",
    "        #Calculating the value of ci2*[theta0_hat + theta_hat.T*X2]-1\n",
    "        constraint_diff2 = self.E2 * self.c2\n",
    "        \n",
    "        #the condition inside not will be true if both constraint as well as lagrange nultiplier will be \n",
    "        #greater than zero hence violating KKT dual complemtarity condition because at a time, either\n",
    "        #constraint has to be zero within some +- tol or lagrange multiplier has to be zero. \n",
    "        if not((contraint_diff2 < -self.tol and self.lambda2 <= self.C) or \n",
    "              (constraint_diff2 > self.tol and self.lambda2 > 0)):\n",
    "            return 0\n",
    "        \n",
    "        non_bound_lagrange_indices = list(self.get_non_bound_indexes())\n",
    "        i1 = self.get_maximum_change_lagrange(non_bound_lagrange_indices)\n",
    "        \n",
    "        if i1>=0 and self.take_cordinate_ascent_step(i1,i2) == True:\n",
    "            return 1\n",
    "        \n",
    "        if len(non_bound_lagrange_indices) > 0:\n",
    "            random_range = randrange(len(non_bound_lagrange_indices))\n",
    "            for i1 in non_bound_lagrange_indices[random_range:] + non_bound_lagrange_indices[:random_range]:\n",
    "                if self.take_cordinate_ascent_step(i1,i2) == True:\n",
    "                    return 1\n",
    "                \n",
    "        random_range = randrange(self.num_lagrange)\n",
    "        all_indices = list(range(self.num_lagrange))\n",
    "        for i1 in all_indices[random_range:] + all_indices[:random_range]:\n",
    "            if self.take_cordinate_ascent_step(i1,i2) == True:\n",
    "                return 1\n",
    "            \n",
    "        return 0\n",
    "            \n",
    "    def smo_algo_main_loop(self):\n",
    "        \n",
    "        num_changed_lagrange = 0\n",
    "        check_all = True\n",
    "        \n",
    "        while num_changed_lagrange > 0 or check_all == True:\n",
    "            num_changed_lagrange = 0\n",
    "            \n",
    "            if check_all == True:\n",
    "                for i in range(self.num_lagrange):\n",
    "                    num_changed_lagrange = num_changed_lagrange + self.check_example(i)\n",
    "            else:\n",
    "                num_changed_lagrange = num_changed_lagrange + self.check_non_bound_lagrange()\n",
    "                \n",
    "            if check_all == True:\n",
    "                check_all = False\n",
    "            elif num_lagrange_changed == 0:\n",
    "                check_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-shipping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
